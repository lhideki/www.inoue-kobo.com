{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各種Tokenize手法に依存したベクトル化手法の比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR\n",
    "\n",
    "以下のベクトル化手法を比較しました。\n",
    "\n",
    "* [wikipedia2vec](https://wikipedia2vec.github.io/wikipedia2vec/)\n",
    "* [sentencepieces + word2vec](https://github.com/google/sentencepiece/blob/master/python/README.md)\n",
    "* [char2vec](https://qiita.com/youwht/items/0b204c3575c94fc786b8)\n",
    "\n",
    "ベクトル化するための学習データとして日本語Wikipediaを使用しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wikipedia2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:49:55.089843Z",
     "start_time": "2018-12-05T13:49:49.720997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1593143\n",
      "[(<Word 脂>, 0.99999994), (<Word 脂肪>, 0.60400623), (<Word 血合>, 0.59330285), (<Word 牛脂>, 0.5907982), (<Word グアヤク>, 0.5891678), (<Word 肪織>, 0.5861825), (<Word グリセリド>, 0.5824453), (<Word ガラスープ>, 0.5739102), (<Word 血合い>, 0.56854814), (<Word 臭み>, 0.5571986)]\n"
     ]
    }
   ],
   "source": [
    "from wikipedia2vec import Wikipedia2Vec\n",
    "\n",
    "word2vec_filename = 'models/jawiki_20180420_300d.pkl'\n",
    "word2vec = Wikipedia2Vec.load(word2vec_filename)\n",
    "\n",
    "test_word = '脂'\n",
    "\n",
    "print(len(word2vec.dictionary))\n",
    "print(word2vec.most_similar(word2vec.get_word(test_word), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentencepieces + word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:49:57.587771Z",
     "start_time": "2018-12-05T13:49:55.091843Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hidek\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171118\n",
      "['▁', '脂']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hidek\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\hidek\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ニンニク', 0.8067691922187805), ('肉', 0.8009461760520935), ('脂肪', 0.7919986248016357), ('ゼリー', 0.786160945892334), ('ゼラチン', 0.7856716513633728), ('臭', 0.7705897688865662), ('粉末状', 0.7692583799362183), ('苦味', 0.7675473093986511), ('ニンジン', 0.7648000717163086), ('汁', 0.7606260776519775)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import sentencepiece as spm\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('models/wikisentence-piece.model')\n",
    "\n",
    "test_word = '脂'\n",
    "tokenized = sp.EncodeAsPieces(test_word)\n",
    "\n",
    "sentencepieced_word2vec_filename = 'models/sentencepieced_word2vec_allwiki.model'\n",
    "sentencepieced_word2vec = Word2Vec.load(sentencepieced_word2vec_filename)\n",
    "\n",
    "print(len(sentencepieced_word2vec.wv.vocab))\n",
    "print(tokenized)\n",
    "print(sentencepieced_word2vec.most_similar(tokenized[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### char2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:49:57.692768Z",
     "start_time": "2018-12-05T13:49:57.589772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hidek\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\hidek\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('糖', 0.9036800861358643), ('繊', 0.7795820832252502), ('剤', 0.7757814526557922), ('汁', 0.7682333588600159), ('酢', 0.7667589783668518), ('塩', 0.7649936676025391), ('酸', 0.7632763981819153), ('粉', 0.7586979269981384), ('菌', 0.751047670841217), ('臭', 0.7475357055664062)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "char2vec_filename = 'models/mychar2vec_fromWikiALL.model'\n",
    "char2vec = Word2Vec.load(char2vec_filename)\n",
    "\n",
    "test_word = '脂'\n",
    "\n",
    "print(len(char2vec.wv.vocab))\n",
    "print(char2vec.most_similar(test_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ベンチマーク用データ\n",
    "\n",
    "[京都大学情報学研究科--NTTコミュニケーション科学基礎研究所 共同研究ユニット](http://nlp.ist.i.kyoto-u.ac.jp/kuntt/index.php)が提供するブログの記事に関するデータセットを利用しました。 このデータセットでは、ブログの記事に対して以下の4つの分類がされています。\n",
    "\n",
    "* グルメ\n",
    "* 携帯電話\n",
    "* 京都\n",
    "* スポーツ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:49:58.138771Z",
     "start_time": "2018-12-05T13:49:57.694769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>［グルメ］烏丸六角のおかき屋さん</td>\n",
       "      <td>グルメ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>六角堂の前にある、蕪村庵というお店に行ってきた。</td>\n",
       "      <td>グルメ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>おかきやせんべいの店なのだが、これがオイシイ。</td>\n",
       "      <td>グルメ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>のれんをくぐると小さな庭があり、その先に町屋風の店内がある。</td>\n",
       "      <td>グルメ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>せんべいの箱はデパートみたいな山積みではなく、間隔をあけて陳列されているのがまた良い。</td>\n",
       "      <td>グルメ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             1 label\n",
       "0                             ［グルメ］烏丸六角のおかき屋さん   グルメ\n",
       "1                     六角堂の前にある、蕪村庵というお店に行ってきた。   グルメ\n",
       "2                      おかきやせんべいの店なのだが、これがオイシイ。   グルメ\n",
       "3               のれんをくぐると小さな庭があり、その先に町屋風の店内がある。   グルメ\n",
       "4  せんべいの箱はデパートみたいな山積みではなく、間隔をあけて陳列されているのがまた良い。   グルメ"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>［携帯電話］プリペイドカード携帯布教。</td>\n",
       "      <td>携帯電話</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>もはや’今さら’だが、という接頭句で始めるしかないほど今さらだが、私はプリペイド携帯をずっと...</td>\n",
       "      <td>携帯電話</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>犯罪に用いられるなどによりかなりイメージを悪化させてしまったプリペイド携帯だが、一ユーザーと...</td>\n",
       "      <td>携帯電話</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>かつてはこのような話を友人に振っても、「携帯電話の料金は親が払っているから別に．．．」という...</td>\n",
       "      <td>携帯電話</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>そこで、携帯電話の料金を自分の身銭で払わざる得ない、あるいは得なくなったが所得が少ない、或い...</td>\n",
       "      <td>携帯電話</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   1 label\n",
       "0                                ［携帯電話］プリペイドカード携帯布教。  携帯電話\n",
       "1  もはや’今さら’だが、という接頭句で始めるしかないほど今さらだが、私はプリペイド携帯をずっと...  携帯電話\n",
       "2  犯罪に用いられるなどによりかなりイメージを悪化させてしまったプリペイド携帯だが、一ユーザーと...  携帯電話\n",
       "3  かつてはこのような話を友人に振っても、「携帯電話の料金は親が払っているから別に．．．」という...  携帯電話\n",
       "4  そこで、携帯電話の料金を自分の身銭で払わざる得ない、あるいは得なくなったが所得が少ない、或い...  携帯電話"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>［京都観光］時雨殿に行った。</td>\n",
       "      <td>京都</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>しぐれでん</td>\n",
       "      <td>京都</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>２００６年１０月０９日。</td>\n",
       "      <td>京都</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>時雨殿に行った。</td>\n",
       "      <td>京都</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>８月に嵐山へドクターフィシュ体験で行った時に残念ながら閉館していたのでいつか行こうと思ってい...</td>\n",
       "      <td>京都</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   1 label\n",
       "0                                     ［京都観光］時雨殿に行った。    京都\n",
       "1                                              しぐれでん    京都\n",
       "2                                       ２００６年１０月０９日。    京都\n",
       "3                                           時雨殿に行った。    京都\n",
       "4  ８月に嵐山へドクターフィシュ体験で行った時に残念ながら閉館していたのでいつか行こうと思ってい...    京都"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>［スポーツ］私の生きがい</td>\n",
       "      <td>スポーツ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>入部３ヶ月目にはじめてのレースを経験した。</td>\n",
       "      <td>スポーツ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>今の１回生では１番漕暦が浅いのに持ち前の体力と精神力でレース出場権を手にした。</td>\n",
       "      <td>スポーツ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>そのレースは東大戦。</td>\n",
       "      <td>スポーツ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>２回生の中に混じっての初レース。</td>\n",
       "      <td>スポーツ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         1 label\n",
       "0                             ［スポーツ］私の生きがい  スポーツ\n",
       "1                    入部３ヶ月目にはじめてのレースを経験した。  スポーツ\n",
       "2  今の１回生では１番漕暦が浅いのに持ち前の体力と精神力でレース出場権を手にした。  スポーツ\n",
       "3                               そのレースは東大戦。  スポーツ\n",
       "4                         ２回生の中に混じっての初レース。  スポーツ"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gourmet_df = pd.read_csv('data/KNBC_v1.0_090925/corpus2/Gourmet.tsv', delimiter='\\t', header=None).drop(columns=[0, 2, 3, 4, 5])\n",
    "keitai_df = pd.read_csv('data/KNBC_v1.0_090925/corpus2/Keitai.tsv', delimiter='\\t', header=None).drop(columns=[0, 2, 3, 4, 5])\n",
    "kyoto_df = pd.read_csv('data/KNBC_v1.0_090925/corpus2/Kyoto.tsv', delimiter='\\t', header=None).drop(columns=[0, 2, 3, 4, 5])\n",
    "sports_df = pd.read_csv('data/KNBC_v1.0_090925/corpus2/Sports.tsv', delimiter='\\t', header=None).drop(columns=[0, 2, 3, 4, 5])\n",
    "\n",
    "gourmet_df['label'] = 'グルメ'\n",
    "keitai_df['label'] = '携帯電話'\n",
    "kyoto_df['label'] = '京都'\n",
    "sports_df['label'] = 'スポーツ'\n",
    "\n",
    "display(gourmet_df.head())\n",
    "display(keitai_df.head())\n",
    "display(kyoto_df.head())\n",
    "display(sports_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:49:58.151757Z",
     "start_time": "2018-12-05T13:49:58.140756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4186\n",
      "4186\n"
     ]
    }
   ],
   "source": [
    "features_readable = []\n",
    "labels = []\n",
    "\n",
    "for p in gourmet_df.values:\n",
    "    features_readable.append(p[0])\n",
    "    labels.append([1, 0, 0, 0])\n",
    "for p in keitai_df.values:\n",
    "    features_readable.append(p[0])\n",
    "    labels.append([0, 1, 0, 0])\n",
    "for p in kyoto_df.values:\n",
    "    features_readable.append(p[0])\n",
    "    labels.append([0, 0, 1, 0])\n",
    "for p in sports_df.values:\n",
    "    features_readable.append(p[0])\n",
    "    labels.append([0, 0, 0, 1])\n",
    "\n",
    "print(len(features_readable))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ベクトル化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wordのベクトル化\n",
    "\n",
    "#### Tokenize\n",
    "\n",
    "word単位のtokenizeは[janome](https://github.com/mocobeta/janome)を使用しました。[NEologd](https://github.com/neologd/mecab-ipadic-neologd)を使用しました。組み込み手順として以下を参考にさせて頂きました。\n",
    "\n",
    "* (very experimental) NEologd 辞書を内包した janome をビルドする方法\n",
    "    * https://github.com/mocobeta/janome/wiki/(very-experimental)-NEologd-%E8%BE%9E%E6%9B%B8%E3%82%92%E5%86%85%E5%8C%85%E3%81%97%E3%81%9F-janome-%E3%82%92%E3%83%93%E3%83%AB%E3%83%89%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95\n",
    "\n",
    "#### ベクトル化\n",
    "\n",
    "[wikipedia2vec](https://wikipedia2vec.github.io/wikipedia2vec/)を使用しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:50:34.765005Z",
     "start_time": "2018-12-05T13:49:58.153755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>［</td>\n",
       "      <td>グルメ</td>\n",
       "      <td>］</td>\n",
       "      <td>烏丸</td>\n",
       "      <td>六角</td>\n",
       "      <td>の</td>\n",
       "      <td>おかき</td>\n",
       "      <td>屋</td>\n",
       "      <td>さん</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>六角堂</td>\n",
       "      <td>の</td>\n",
       "      <td>前</td>\n",
       "      <td>に</td>\n",
       "      <td>ある</td>\n",
       "      <td>、</td>\n",
       "      <td>蕪村</td>\n",
       "      <td>庵</td>\n",
       "      <td>という</td>\n",
       "      <td>お</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>おかき</td>\n",
       "      <td>や</td>\n",
       "      <td>せんべい</td>\n",
       "      <td>の</td>\n",
       "      <td>店</td>\n",
       "      <td>だ</td>\n",
       "      <td>の</td>\n",
       "      <td>だ</td>\n",
       "      <td>が</td>\n",
       "      <td>、</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>のれん</td>\n",
       "      <td>を</td>\n",
       "      <td>くぐる</td>\n",
       "      <td>と</td>\n",
       "      <td>小さな</td>\n",
       "      <td>庭</td>\n",
       "      <td>が</td>\n",
       "      <td>ある</td>\n",
       "      <td>、</td>\n",
       "      <td>その</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>せんべい</td>\n",
       "      <td>の</td>\n",
       "      <td>箱</td>\n",
       "      <td>は</td>\n",
       "      <td>デパート</td>\n",
       "      <td>みたい</td>\n",
       "      <td>だ</td>\n",
       "      <td>山積み</td>\n",
       "      <td>で</td>\n",
       "      <td>は</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1     2   3     4    5    6    7    8     9    ...    118   119  \\\n",
       "0     ［  グルメ     ］  烏丸    六角    の  おかき    屋   さん  None  ...   None  None   \n",
       "1   六角堂    の     前   に    ある    、   蕪村    庵  という     お  ...   None  None   \n",
       "2   おかき    や  せんべい   の     店    だ    の    だ    が     、  ...   None  None   \n",
       "3   のれん    を   くぐる   と   小さな    庭    が   ある    、    その  ...   None  None   \n",
       "4  せんべい    の     箱   は  デパート  みたい    だ  山積み    で     は  ...   None  None   \n",
       "\n",
       "    120   121   122   123   124   125   126   127  \n",
       "0  None  None  None  None  None  None  None  None  \n",
       "1  None  None  None  None  None  None  None  None  \n",
       "2  None  None  None  None  None  None  None  None  \n",
       "3  None  None  None  None  None  None  None  None  \n",
       "4  None  None  None  None  None  None  None  None  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = Tokenizer(mmap=True)\n",
    "\n",
    "def get_word_tokens(df):\n",
    "    all_tokens = []\n",
    "    for sentence in df[:][0]:\n",
    "        tokens = tokenizer.tokenize(sentence)\n",
    "        base_forms = [token.base_form for token in tokens]\n",
    "        all_tokens.append(base_forms)\n",
    "\n",
    "    return all_tokens\n",
    "\n",
    "word_tokenized_features = get_word_tokens(pd.DataFrame(features_readable))\n",
    "display(pd.DataFrame(word_tokenized_features).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:50:35.517969Z",
     "start_time": "2018-12-05T13:50:34.766990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4186, 128, 300)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "words_maxlen = len(max(word_tokenized_features, key = (lambda x: len(x))))\n",
    "\n",
    "word_features_vector = np.zeros((len(word_tokenized_features), words_maxlen, word2vec.get_word_vector('脂').shape[0]), dtype = np.int32)\n",
    "for i, tokens in enumerate(word_tokenized_features):\n",
    "    for t, token in enumerate(tokens):\n",
    "        if not token or token == ' ':\n",
    "            continue\n",
    "        try:\n",
    "            word_features_vector[i, t] = word2vec.get_word_vector(token.lower())\n",
    "        except:\n",
    "            #logging.warn(f'{token} is skipped.')\n",
    "            continue\n",
    "\n",
    "print(word_features_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentencepieceのベクトル化\n",
    "\n",
    "#### Tokenize\n",
    "\n",
    "[sentencepiece + word2vec](https://github.com/google/sentencepiece/blob/master/python/README.md)を使用しました。\n",
    "sentencepieceの学習には日本語Wikipediaを使用しています。\n",
    "\n",
    "#### ベクトル化\n",
    "\n",
    "sentencepiecesでtokenizeした上で、日本語Wikipediaを対象にword2vecで学習しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:50:35.717964Z",
     "start_time": "2018-12-05T13:50:35.518968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁[</td>\n",
       "      <td>グルメ</td>\n",
       "      <td>]</td>\n",
       "      <td>烏丸</td>\n",
       "      <td>六角</td>\n",
       "      <td>のお</td>\n",
       "      <td>かき</td>\n",
       "      <td>屋さん</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁</td>\n",
       "      <td>六角</td>\n",
       "      <td>堂</td>\n",
       "      <td>の前</td>\n",
       "      <td>にある</td>\n",
       "      <td>、</td>\n",
       "      <td>蕪</td>\n",
       "      <td>村</td>\n",
       "      <td>庵</td>\n",
       "      <td>という</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>▁</td>\n",
       "      <td>おか</td>\n",
       "      <td>き</td>\n",
       "      <td>や</td>\n",
       "      <td>せんべい</td>\n",
       "      <td>の</td>\n",
       "      <td>店</td>\n",
       "      <td>な</td>\n",
       "      <td>のだが</td>\n",
       "      <td>、</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>▁</td>\n",
       "      <td>の</td>\n",
       "      <td>れん</td>\n",
       "      <td>をくぐる</td>\n",
       "      <td>と</td>\n",
       "      <td>小さな</td>\n",
       "      <td>庭</td>\n",
       "      <td>があり</td>\n",
       "      <td>、</td>\n",
       "      <td>その先に</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>▁</td>\n",
       "      <td>せんべい</td>\n",
       "      <td>の</td>\n",
       "      <td>箱</td>\n",
       "      <td>は</td>\n",
       "      <td>デパート</td>\n",
       "      <td>みたいな</td>\n",
       "      <td>山</td>\n",
       "      <td>積み</td>\n",
       "      <td>ではなく</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1   2     3     4     5     6    7     8     9   ...     86    87  \\\n",
       "0  ▁[   グルメ   ]    烏丸    六角    のお    かき  屋さん  None  None  ...   None  None   \n",
       "1   ▁    六角   堂    の前   にある     、     蕪    村     庵   という  ...   None  None   \n",
       "2   ▁    おか   き     や  せんべい     の     店    な   のだが     、  ...   None  None   \n",
       "3   ▁     の  れん  をくぐる     と   小さな     庭  があり     、  その先に  ...   None  None   \n",
       "4   ▁  せんべい   の     箱     は  デパート  みたいな    山    積み  ではなく  ...   None  None   \n",
       "\n",
       "     88    89    90    91    92    93    94    95  \n",
       "0  None  None  None  None  None  None  None  None  \n",
       "1  None  None  None  None  None  None  None  None  \n",
       "2  None  None  None  None  None  None  None  None  \n",
       "3  None  None  None  None  None  None  None  None  \n",
       "4  None  None  None  None  None  None  None  None  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "def get_sentencepieced_word_tokens(df):\n",
    "    all_tokens = []\n",
    "    for sentence in df[:][0]:\n",
    "        tokens = sp.EncodeAsPieces(sentence)\n",
    "        all_tokens.append(tokens)\n",
    "\n",
    "    return all_tokens\n",
    "\n",
    "sentencepieced_word_tokenized_features = get_sentencepieced_word_tokens(pd.DataFrame(features_readable))\n",
    "display(pd.DataFrame(sentencepieced_word_tokenized_features).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:50:36.090968Z",
     "start_time": "2018-12-05T13:50:35.719964Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hidek\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4186, 96, 50)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "sentencepieced_word_maxlen = len(max(sentencepieced_word_tokenized_features, key = (lambda x: len(x))))\n",
    "\n",
    "sentencepieced_word_features = np.zeros((len(sentencepieced_word_tokenized_features), sentencepieced_word_maxlen, sentencepieced_word2vec.wv.vectors.shape[1]), dtype = np.int32)\n",
    "for i, tokens in enumerate(sentencepieced_word_tokenized_features):\n",
    "    for t, token in enumerate(tokens):\n",
    "        if not token or token == ' ' :\n",
    "            continue\n",
    "        try:\n",
    "            sentencepieced_word_features[i, t] = sentencepieced_word2vec[token.lower()]\n",
    "        except:\n",
    "            #logging.warn(f'{type(token)}->{token} is skipped.')\n",
    "            continue\n",
    "\n",
    "print(sentencepieced_word_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### characterのベクトル化\n",
    "\n",
    "#### Tokenize\n",
    "\n",
    "単純に1文字ずつ分解しました。\n",
    "\n",
    "#### ベクトル化\n",
    "\n",
    "[char2vec](https://qiita.com/youwht/items/0b204c3575c94fc786b8)を参考に、日本語Wikipediaを対象にword2vecで学習しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:50:36.749934Z",
     "start_time": "2018-12-05T13:50:36.091952Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hidek\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4186, 228, 30)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "chars_maxlen = len(max(features_readable, key = (lambda x: len(x))))\n",
    "\n",
    "char_features_vector = np.zeros((len(features_readable), chars_maxlen, char2vec.wv.vectors.shape[1]), dtype = np.int32)\n",
    "for i, text in enumerate(features_readable):\n",
    "    for t, token in enumerate(text):\n",
    "        if token == ' ':\n",
    "            continue\n",
    "        try:\n",
    "            char_features_vector[i, t] = char2vec[token.lower()]\n",
    "        except:\n",
    "            #logging.warn(f'{char} is skipped.')\n",
    "            continue\n",
    "\n",
    "print(char_features_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データと検証データの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:50:37.629923Z",
     "start_time": "2018-12-05T13:50:36.750934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3767, 128, 300)\n",
      "(419, 128, 300)\n",
      "(3767, 96, 50)\n",
      "(419, 96, 50)\n",
      "(3767, 228, 30)\n",
      "(419, 228, 30)\n",
      "(3767, 4)\n",
      "(419, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "idx_features = range(len(features_readable))\n",
    "idx_labels = range(len(labels))\n",
    "tmp_data = train_test_split(idx_features, idx_labels, train_size = 0.9, test_size = 0.1)\n",
    "\n",
    "train_char_features = np.array([char_features_vector[i] for i in tmp_data[0]])\n",
    "valid_char_features = np.array([char_features_vector[i] for i in tmp_data[1]])\n",
    "train_word_features = np.array([word_features_vector[i] for i in tmp_data[0]])\n",
    "valid_word_features = np.array([word_features_vector[i] for i in tmp_data[1]])\n",
    "train_sentencepieced_word_features = np.array([sentencepieced_word_features[i] for i in tmp_data[0]])\n",
    "valid_sentencepieced_word_features = np.array([sentencepieced_word_features[i] for i in tmp_data[1]])\n",
    "train_labels = np.array([labels[i] for i in tmp_data[2]])\n",
    "valid_labels = np.array([labels[i] for i in tmp_data[3]])\n",
    "\n",
    "print(train_word_features.shape)\n",
    "print(valid_word_features.shape)\n",
    "print(train_sentencepieced_word_features.shape)\n",
    "print(valid_sentencepieced_word_features.shape)\n",
    "print(train_char_features.shape)\n",
    "print(valid_char_features.shape)\n",
    "print(train_labels.shape)\n",
    "print(valid_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワーク設計\n",
    "\n",
    "比較できるようにBi-LSTM+全結合で統一しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:50:39.324870Z",
     "start_time": "2018-12-05T13:50:37.631916Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hidek\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional\n",
    "from keras import Input, Model\n",
    "\n",
    "def create_model(train_features):\n",
    "    class_count = 4\n",
    "\n",
    "    input_tensor = Input(train_features[0].shape)\n",
    "    x1 = Bidirectional(LSTM(512))(input_tensor)\n",
    "    x1 = Dense(2048)(x1)\n",
    "    x1 = Dropout(0.5)(x1)\n",
    "    output_tensor = Dense(class_count, activation='softmax')(x1)\n",
    "\n",
    "    model = Model(input_tensor, output_tensor)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word単位のベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:51:43.809842Z",
     "start_time": "2018-12-05T13:50:39.325860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1024)              3330048   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 8196      \n",
      "=================================================================\n",
      "Total params: 5,437,444\n",
      "Trainable params: 5,437,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "model = create_model(train_word_features)\n",
    "history = model.fit(train_word_features,\n",
    "          train_labels,\n",
    "          epochs = 100,\n",
    "          batch_size = 128,\n",
    "          validation_split = 0.1,\n",
    "          verbose = 0,\n",
    "          callbacks = [\n",
    "              TensorBoard(log_dir = 'tflogs'),\n",
    "              EarlyStopping(patience=3, monitor='val_mean_absolute_error'),\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:51:43.827852Z",
     "start_time": "2018-12-05T13:51:43.811843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.50071</td>\n",
       "      <td>0.356764</td>\n",
       "      <td>2.960723</td>\n",
       "      <td>0.357099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.50071</td>\n",
       "      <td>0.356764</td>\n",
       "      <td>11.206593</td>\n",
       "      <td>0.347640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.50071</td>\n",
       "      <td>0.356764</td>\n",
       "      <td>11.206593</td>\n",
       "      <td>0.347640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.50071</td>\n",
       "      <td>0.356764</td>\n",
       "      <td>11.206593</td>\n",
       "      <td>0.347640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_loss  val_mean_absolute_error       loss  mean_absolute_error\n",
       "0  11.50071                 0.356764   2.960723             0.357099\n",
       "1  11.50071                 0.356764  11.206593             0.347640\n",
       "2  11.50071                 0.356764  11.206593             0.347640\n",
       "3  11.50071                 0.356764  11.206593             0.347640"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### クラシフィケーションレポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:51:45.913783Z",
     "start_time": "2018-12-05T13:51:43.829842Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hidek\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        グルメ       0.00      0.00      0.00        79\n",
      "       携帯電話       0.33      1.00      0.49       137\n",
      "         京都       0.00      0.00      0.00       159\n",
      "       スポーツ       0.00      0.00      0.00        44\n",
      "\n",
      "avg / total       0.11      0.33      0.16       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "predicted_valid_labels = model.predict(valid_word_features).argmax(axis=1)\n",
    "numeric_valid_labels = np.array(valid_labels).argmax(axis=1)\n",
    "print(classification_report(numeric_valid_labels, predicted_valid_labels, target_names = ['グルメ', '携帯電話', '京都', 'スポーツ']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentencepiece単位のベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:53:12.104961Z",
     "start_time": "2018-12-05T13:51:45.914783Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 96, 50)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 1024)              2306048   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 8196      \n",
      "=================================================================\n",
      "Total params: 4,413,444\n",
      "Trainable params: 4,413,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "model = create_model(train_sentencepieced_word_features)\n",
    "history = model.fit(train_sentencepieced_word_features,\n",
    "          train_labels,\n",
    "          epochs = 100,\n",
    "          batch_size = 128,\n",
    "          validation_split = 0.1,\n",
    "          verbose = 0,\n",
    "          callbacks = [\n",
    "              TensorBoard(log_dir = 'tflogs'),\n",
    "              EarlyStopping(patience=3, monitor='val_mean_absolute_error'),\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:53:12.118961Z",
     "start_time": "2018-12-05T13:53:12.106962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.956627</td>\n",
       "      <td>0.221953</td>\n",
       "      <td>1.326010</td>\n",
       "      <td>0.247198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.797366</td>\n",
       "      <td>0.184630</td>\n",
       "      <td>0.707562</td>\n",
       "      <td>0.179766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.955078</td>\n",
       "      <td>0.184920</td>\n",
       "      <td>0.575998</td>\n",
       "      <td>0.149156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.816159</td>\n",
       "      <td>0.160946</td>\n",
       "      <td>0.460184</td>\n",
       "      <td>0.119154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.892578</td>\n",
       "      <td>0.161730</td>\n",
       "      <td>0.374453</td>\n",
       "      <td>0.098004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.044131</td>\n",
       "      <td>0.153019</td>\n",
       "      <td>0.235490</td>\n",
       "      <td>0.065125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.193457</td>\n",
       "      <td>0.154924</td>\n",
       "      <td>0.148180</td>\n",
       "      <td>0.040250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.323699</td>\n",
       "      <td>0.154288</td>\n",
       "      <td>0.114584</td>\n",
       "      <td>0.029999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.507059</td>\n",
       "      <td>0.158151</td>\n",
       "      <td>0.098657</td>\n",
       "      <td>0.024973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_loss  val_mean_absolute_error      loss  mean_absolute_error\n",
       "0  0.956627                 0.221953  1.326010             0.247198\n",
       "1  0.797366                 0.184630  0.707562             0.179766\n",
       "2  0.955078                 0.184920  0.575998             0.149156\n",
       "3  0.816159                 0.160946  0.460184             0.119154\n",
       "4  0.892578                 0.161730  0.374453             0.098004\n",
       "5  1.044131                 0.153019  0.235490             0.065125\n",
       "6  1.193457                 0.154924  0.148180             0.040250\n",
       "7  1.323699                 0.154288  0.114584             0.029999\n",
       "8  1.507059                 0.158151  0.098657             0.024973"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### クラシフィケーションレポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:53:13.801246Z",
     "start_time": "2018-12-05T13:53:12.121961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        グルメ       0.55      0.71      0.62        79\n",
      "       携帯電話       0.86      0.70      0.77       137\n",
      "         京都       0.72      0.72      0.72       159\n",
      "       スポーツ       0.60      0.66      0.63        44\n",
      "\n",
      "avg / total       0.73      0.71      0.71       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "predicted_valid_labels = model.predict(valid_sentencepieced_word_features).argmax(axis=1)\n",
    "numeric_valid_labels = np.array(valid_labels).argmax(axis=1)\n",
    "print(classification_report(numeric_valid_labels, predicted_valid_labels, target_names = ['グルメ', '携帯電話', '京都', 'スポーツ']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### character単位のベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:58:12.631796Z",
     "start_time": "2018-12-05T13:53:13.803245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 228, 30)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 1024)              2224128   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 8196      \n",
      "=================================================================\n",
      "Total params: 4,331,524\n",
      "Trainable params: 4,331,524\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "model = create_model(train_char_features)\n",
    "history = model.fit(train_char_features,\n",
    "          train_labels,\n",
    "          epochs = 100,\n",
    "          batch_size = 128,\n",
    "          validation_split = 0.1,\n",
    "          verbose = 0,\n",
    "          callbacks = [\n",
    "              TensorBoard(log_dir = 'tflogs'),\n",
    "              EarlyStopping(patience=3, monitor='val_mean_absolute_error'),\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:58:12.647796Z",
     "start_time": "2018-12-05T13:58:12.632796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.133514</td>\n",
       "      <td>0.260941</td>\n",
       "      <td>1.511209</td>\n",
       "      <td>0.294927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.031117</td>\n",
       "      <td>0.242494</td>\n",
       "      <td>0.885137</td>\n",
       "      <td>0.223371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.033733</td>\n",
       "      <td>0.213774</td>\n",
       "      <td>0.670592</td>\n",
       "      <td>0.172283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.134447</td>\n",
       "      <td>0.195758</td>\n",
       "      <td>0.465304</td>\n",
       "      <td>0.123497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.322540</td>\n",
       "      <td>0.190850</td>\n",
       "      <td>0.323370</td>\n",
       "      <td>0.085696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.444636</td>\n",
       "      <td>0.186323</td>\n",
       "      <td>0.211693</td>\n",
       "      <td>0.057552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.454644</td>\n",
       "      <td>0.194053</td>\n",
       "      <td>0.462514</td>\n",
       "      <td>0.064610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.364223</td>\n",
       "      <td>0.188317</td>\n",
       "      <td>0.375528</td>\n",
       "      <td>0.064455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.542475</td>\n",
       "      <td>0.182408</td>\n",
       "      <td>0.132808</td>\n",
       "      <td>0.033755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.684466</td>\n",
       "      <td>0.187286</td>\n",
       "      <td>0.104973</td>\n",
       "      <td>0.024736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.561364</td>\n",
       "      <td>0.170014</td>\n",
       "      <td>0.079682</td>\n",
       "      <td>0.018421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.958930</td>\n",
       "      <td>0.185263</td>\n",
       "      <td>0.071481</td>\n",
       "      <td>0.014887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.003443</td>\n",
       "      <td>0.184295</td>\n",
       "      <td>0.078971</td>\n",
       "      <td>0.015059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.181898</td>\n",
       "      <td>0.188742</td>\n",
       "      <td>0.077126</td>\n",
       "      <td>0.014577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    val_loss  val_mean_absolute_error      loss  mean_absolute_error\n",
       "0   1.133514                 0.260941  1.511209             0.294927\n",
       "1   1.031117                 0.242494  0.885137             0.223371\n",
       "2   1.033733                 0.213774  0.670592             0.172283\n",
       "3   1.134447                 0.195758  0.465304             0.123497\n",
       "4   1.322540                 0.190850  0.323370             0.085696\n",
       "5   1.444636                 0.186323  0.211693             0.057552\n",
       "6   1.454644                 0.194053  0.462514             0.064610\n",
       "7   1.364223                 0.188317  0.375528             0.064455\n",
       "8   1.542475                 0.182408  0.132808             0.033755\n",
       "9   1.684466                 0.187286  0.104973             0.024736\n",
       "10  1.561364                 0.170014  0.079682             0.018421\n",
       "11  1.958930                 0.185263  0.071481             0.014887\n",
       "12  2.003443                 0.184295  0.078971             0.015059\n",
       "13  2.181898                 0.188742  0.077126             0.014577"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### クラシフィケーションレポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:58:16.176694Z",
     "start_time": "2018-12-05T13:58:12.649799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        グルメ       0.55      0.65      0.60        79\n",
      "       携帯電話       0.62      0.67      0.65       137\n",
      "         京都       0.72      0.53      0.61       159\n",
      "       スポーツ       0.29      0.41      0.34        44\n",
      "\n",
      "avg / total       0.61      0.58      0.59       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "predicted_valid_labels = model.predict(valid_char_features).argmax(axis=1)\n",
    "numeric_valid_labels = np.array(valid_labels).argmax(axis=1)\n",
    "print(classification_report(numeric_valid_labels, predicted_valid_labels, target_names = ['グルメ', '携帯電話', '京都', 'スポーツ']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 総括\n",
    "\n",
    "それぞれクラシフィケーションレポートの結果は以下の通りです。\n",
    "今回の結果からは`sentencepiece`の優位性が確認できました。\n",
    "`character`も悪くはないのですが、精度的に`sentencepiece`よりも悪い上に入力信号が長くなるので学習時間が長くかかります。\n",
    "\n",
    "ただ、`word`の結果が悪すぎるので何か間違っている気がします・・・。問題に気付いた方はご指摘いただけると助かります。\n",
    "\n",
    "### word\n",
    "\n",
    "![](images/word_results.png)\n",
    "\n",
    "### sentencepiece\n",
    "\n",
    "![](images/sentencepiece_results.png)\n",
    "\n",
    "### character\n",
    "\n",
    "![](images/char_results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo\n",
    "\n",
    "[国立国語研究所](https://www.ninjal.ac.jp/)のコーパスを使って比較してみたいと考えています。\n",
    "良い結果が得られるようであれば、学習済みモデルも公開したいです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "* [wikipedia2vec](https://wikipedia2vec.github.io/wikipedia2vec/)\n",
    "* [sentencepieces + word2vec](https://github.com/google/sentencepiece/blob/master/python/README.md)\n",
    "* [char2vec](https://qiita.com/youwht/items/0b204c3575c94fc786b8)\n",
    "* [janome](https://github.com/mocobeta/janome)\n",
    "* [NEologd](https://github.com/neologd/mecab-ipadic-neologd)\n",
    "* (very experimental) NEologd 辞書を内包した janome をビルドする方法\n",
    "    * https://github.com/mocobeta/janome/wiki/(very-experimental)-NEologd-%E8%BE%9E%E6%9B%B8%E3%82%92%E5%86%85%E5%8C%85%E3%81%97%E3%81%9F-janome-%E3%82%92%E3%83%93%E3%83%AB%E3%83%89%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
